(pytorch) [lhg256@cuda2 code]$ nvprof ./bin/conv_exp -n -a sparse ./data/128.mat ./data/k3_0.mat 
iterations_flag = 1, alg_type_flag = sparse
Non-option argument ./data/128.mat
Non-option argument ./data/k3_0.mat
optind:4,argc:6
==49599== NVPROF is profiling process 49599, command: ./bin/conv_exp -n -a sparse ./data/128.mat ./data/k3_0.mat
Number of iterations: 1000
 ============= SPARSE KERNEL, TILED CONVOLUTION =============== 
Time taken to create handle: 10.910000 
Spm on device? 1
No pitch, pitch is: 0
Kernel is ALREADY on the device.
Grid dim: (8, 8), block dim: (18, 18)
Total threads: 20736
Actual matrix width: 128
Shared mem is: 333 elems, tile: 324, kernel: 9
Time taken to allocate mem and copy to device: 0.010000 
Time taken to execute kernel: 0.010000 
Time taken to copy memory back to host and free device mem: 0.000000 
Time taken to convert matrix: 0.010000 
Time taken to convolve matrix: 0.020000 
Time taken is 10.940000
Time taken per iteration 0.010940
==49599== Profiling application: ./bin/conv_exp -n -a sparse ./data/128.mat ./data/k3_0.mat
==49599== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 98.85%  3.5931ms      1000  3.5930us  3.5200us  5.2160us  convolve2DKernelSparse(float*, float*, int*, int*, int, float*, int, int, int, int, int)
  0.26%  9.4090us         2  4.7040us  1.9840us  7.4250us  [CUDA memcpy DtoH]
  0.25%  9.2160us         2  4.6080us  1.0240us  8.1920us  [CUDA memcpy HtoD]
  0.11%  3.9040us         1  3.9040us  3.9040us  3.9040us  void cusparseIinclusive_scan_domino_v1_core<int=256, int=4>(int, int*, int*, int*, int*, int*)
  0.10%  3.6160us         1  3.6160us  3.6160us  3.6160us  void cusparseParseDenseByRows_kernel<float, int=0>(int, int, float const *, int, int*)
  0.09%  3.3280us         1  3.3280us  3.3280us  3.3280us  void cusparseIinclusive_localscan_core<int=256, int=4>(int, int*, int*, int*)
  0.09%  3.1320us         5     626ns     404ns     884ns  [CUDA memset]
  0.08%  2.8160us         1  2.8160us  2.8160us  2.8160us  void cusparseIreduce_domino_core<int=256, int=4>(int, int*, int*, int*, int*)
  0.07%  2.6880us         1  2.6880us  2.6880us  2.6880us  void cusparseDenseToCsr_kernel2<float, int=4, int=32, int=0>(int, int, float const *, int, int const *, int*, float*)
  0.05%  1.9520us         1  1.9520us  1.9520us  1.9520us  cusparseDense2CsrCopySetBase_kernel(int const *, int*, int, int)
  0.05%  1.6640us         1  1.6640us  1.6640us  1.6640us  void cusparseIinclusive_scan_merge_core<int=256, int=4>(int, int, int*, int*, int*)

==49599== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.70%  11.1972s        12  933.10ms  3.4720us  10.9037s  cudaFree
  0.09%  10.560ms         1  10.560ms  10.560ms  10.560ms  cudaDeviceSynchronize
  0.06%  6.4691ms      1007  6.4240us  5.5790us  69.453us  cudaLaunch
  0.06%  6.3878ms         4  1.5970ms  35.297us  4.7842ms  cudaMemcpy
  0.05%  5.1405ms       664  7.7410us     111ns  341.23us  cuDeviceGetAttribute
  0.02%  2.3464ms     11036     212ns     139ns  12.281us  cudaSetupArgument
  0.01%  1.4106ms         8  176.33us  76.610us  270.63us  cuDeviceTotalMem
  0.01%  639.41us         9  71.045us  8.0570us  332.20us  cudaMalloc
  0.00%  495.80us         8  61.975us  48.842us  69.634us  cuDeviceGetName
  0.00%  239.65us      1007     237ns     165ns  7.6620us  cudaConfigureCall
  0.00%  23.884us         4  5.9710us  2.2590us  14.121us  cudaMemsetAsync
  0.00%  22.080us         3  7.3600us  3.3880us  15.251us  cudaFuncGetAttributes
  0.00%  12.679us        10  1.2670us     256ns  9.3070us  cudaDeviceGetAttribute
  0.00%  8.9960us         1  8.9960us  8.9960us  8.9960us  cudaMemset
  0.00%  4.3620us        12     363ns     167ns     683ns  cuDeviceGet
  0.00%  3.6750us         3  1.2250us     326ns  2.9270us  cuDeviceGetCount
  0.00%  2.5970us         9     288ns     145ns     927ns  cudaGetLastError
  0.00%  2.5420us         1  2.5420us  2.5420us  2.5420us  cudaGetDevice
  0.00%     778ns         1     778ns     778ns     778ns  cuInit
  0.00%     650ns         1     650ns     650ns     650ns  cuDriverGetVersion
(pytorch) [lhg256@cuda2 code]$ nvprof ./bin/conv_exp -n -a sparse ./data/224.mat ./data/k3_0.mat 
iterations_flag = 1, alg_type_flag = sparse
Non-option argument ./data/224.mat
Non-option argument ./data/k3_0.mat
optind:4,argc:6
==49636== NVPROF is profiling process 49636, command: ./bin/conv_exp -n -a sparse ./data/224.mat ./data/k3_0.mat
Number of iterations: 1000
 ============= SPARSE KERNEL, TILED CONVOLUTION =============== 
Time taken to create handle: 10.990000 
Spm on device? 1
No pitch, pitch is: 0
Kernel is ALREADY on the device.
Grid dim: (14, 14), block dim: (18, 18)
Total threads: 63504
Actual matrix width: 224
Shared mem is: 333 elems, tile: 324, kernel: 9
Time taken to allocate mem and copy to device: 0.000000 
Time taken to execute kernel: 0.030000 
Time taken to copy memory back to host and free device mem: 0.000000 
Time taken to convert matrix: 0.020000 
Time taken to convolve matrix: 0.030000 
Time taken is 11.040000
Time taken per iteration 0.011040
==49636== Profiling application: ./bin/conv_exp -n -a sparse ./data/224.mat ./data/k3_0.mat
==49636== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.56%  14.448ms      1000  14.448us  7.7440us  2.2595ms  convolve2DKernelSparse(float*, float*, int*, int*, int, float*, int, int, int, int, int)
  0.14%  20.448us         2  10.224us  1.0560us  19.392us  [CUDA memcpy HtoD]
  0.14%  20.288us         2  10.144us  2.0480us  18.240us  [CUDA memcpy DtoH]
  0.02%  3.5200us         1  3.5200us  3.5200us  3.5200us  void cusparseParseDenseByRows_kernel<float, int=0>(int, int, float const *, int, int*)
  0.02%  3.5200us         1  3.5200us  3.5200us  3.5200us  void cusparseIinclusive_scan_domino_v1_core<int=256, int=4>(int, int*, int*, int*, int*, int*)
  0.02%  3.4560us         1  3.4560us  3.4560us  3.4560us  void cusparseIinclusive_localscan_core<int=256, int=4>(int, int*, int*, int*)
  0.02%  3.1740us         5     634ns     349ns  1.0300us  [CUDA memset]
  0.02%  3.0720us         1  3.0720us  3.0720us  3.0720us  void cusparseIreduce_domino_core<int=256, int=4>(int, int*, int*, int*, int*)
  0.02%  2.8160us         1  2.8160us  2.8160us  2.8160us  void cusparseDenseToCsr_kernel2<float, int=4, int=32, int=0>(int, int, float const *, int, int const *, int*, float*)
  0.01%  2.1760us         1  2.1760us  2.1760us  2.1760us  cusparseDense2CsrCopySetBase_kernel(int const *, int*, int, int)
  0.01%  1.7930us         1  1.7930us  1.7930us  1.7930us  void cusparseIinclusive_scan_merge_core<int=256, int=4>(int, int, int*, int*, int*)

==49636== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.61%  11.2801s        12  940.01ms  3.8790us  10.9868s  cudaFree
  0.20%  22.356ms         1  22.356ms  22.356ms  22.356ms  cudaDeviceSynchronize
  0.06%  6.4239ms      1007  6.3790us  5.4170us  60.937us  cudaLaunch
  0.05%  5.6050ms         4  1.4013ms  110.52us  3.9183ms  cudaMemcpy
  0.04%  4.6899ms       664  7.0630us     110ns  291.41us  cuDeviceGetAttribute
  0.02%  2.2814ms     11036     206ns     138ns  13.977us  cudaSetupArgument
  0.01%  1.2433ms         8  155.41us  75.744us  217.07us  cuDeviceTotalMem
  0.01%  683.68us         9  75.963us  7.3010us  386.90us  cudaMalloc
  0.00%  453.33us         8  56.666us  48.908us  62.668us  cuDeviceGetName
  0.00%  223.41us      1007     221ns     181ns  6.1880us  cudaConfigureCall
  0.00%  46.036us         3  15.345us  10.380us  19.872us  cudaFuncGetAttributes
  0.00%  33.816us         1  33.816us  33.816us  33.816us  cudaMemset
  0.00%  21.854us         4  5.4630us  2.2890us  12.124us  cudaMemsetAsync
  0.00%  6.9190us        10     691ns     265ns  3.4950us  cudaDeviceGetAttribute
  0.00%  3.8150us         3  1.2710us     293ns  3.1700us  cuDeviceGetCount
  0.00%  3.1830us        12     265ns     136ns     484ns  cuDeviceGet
  0.00%  2.8860us         1  2.8860us  2.8860us  2.8860us  cudaGetDevice
  0.00%  2.4180us         9     268ns     152ns     759ns  cudaGetLastError
  0.00%     802ns         1     802ns     802ns     802ns  cuInit
  0.00%     777ns         1     777ns     777ns     777ns  cuDriverGetVersion
(pytorch) [lhg256@cuda2 code]$ nvprof ./bin/conv_exp -n -a sparse ./data/512.mat ./data/k3_0.mat 
iterations_flag = 1, alg_type_flag = sparse
Non-option argument ./data/512.mat
Non-option argument ./data/k3_0.mat
optind:4,argc:6
==49657== NVPROF is profiling process 49657, command: ./bin/conv_exp -n -a sparse ./data/512.mat ./data/k3_0.mat
Number of iterations: 1000
 ============= SPARSE KERNEL, TILED CONVOLUTION =============== 
Time taken to create handle: 10.910000 
Spm on device? 1
No pitch, pitch is: 0
Kernel is ALREADY on the device.
Grid dim: (32, 32), block dim: (18, 18)
Total threads: 331776
Actual matrix width: 512
Shared mem is: 333 elems, tile: 324, kernel: 9
Time taken to allocate mem and copy to device: 0.000000 
Time taken to execute kernel: 0.120000 
Time taken to copy memory back to host and free device mem: 0.000000 
Time taken to convert matrix: 0.010000 
Time taken to convolve matrix: 0.120000 
Time taken is 11.040000
Time taken per iteration 0.011040
==49657== Profiling application: ./bin/conv_exp -n -a sparse ./data/512.mat ./data/k3_0.mat
==49657== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.78%  88.231ms      1000  88.231us  31.649us  3.7642ms  convolve2DKernelSparse(float*, float*, int*, int*, int, float*, int, int, int, int, int)
  0.10%  88.928us         2  44.464us  1.0560us  87.872us  [CUDA memcpy HtoD]
  0.10%  86.465us         2  43.232us  2.0160us  84.449us  [CUDA memcpy DtoH]
  0.00%  3.6510us         5     730ns     405ns  1.0830us  [CUDA memset]
  0.00%  3.3920us         1  3.3920us  3.3920us  3.3920us  void cusparseIinclusive_scan_domino_v1_core<int=256, int=4>(int, int*, int*, int*, int*, int*)
  0.00%  3.3920us         1  3.3920us  3.3920us  3.3920us  void cusparseIinclusive_localscan_core<int=256, int=4>(int, int*, int*, int*)
  0.00%  3.2320us         1  3.2320us  3.2320us  3.2320us  void cusparseParseDenseByRows_kernel<float, int=0>(int, int, float const *, int, int*)
  0.00%  2.7520us         1  2.7520us  2.7520us  2.7520us  void cusparseIreduce_domino_core<int=256, int=4>(int, int*, int*, int*, int*)
  0.00%  2.6560us         1  2.6560us  2.6560us  2.6560us  void cusparseDenseToCsr_kernel2<float, int=4, int=32, int=0>(int, int, float const *, int, int const *, int*, float*)
  0.00%  2.0800us         1  2.0800us  2.0800us  2.0800us  cusparseDense2CsrCopySetBase_kernel(int const *, int*, int, int)
  0.00%  1.9200us         1  1.9200us  1.9200us  1.9200us  void cusparseIinclusive_scan_merge_core<int=256, int=4>(int, int, int*, int*, int*)

==49657== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 98.92%  11.2097s        12  934.14ms  5.2570us  10.8979s  cudaFree
  0.88%  99.947ms         1  99.947ms  99.947ms  99.947ms  cudaDeviceSynchronize
  0.06%  6.6855ms         4  1.6714ms  248.01us  4.7749ms  cudaMemcpy
  0.05%  5.8872ms      1007  5.8460us  5.1120us  56.345us  cudaLaunch
  0.04%  4.4552ms       664  6.7090us     129ns  292.68us  cuDeviceGetAttribute
  0.02%  2.5655ms     11036     232ns     158ns  14.457us  cudaSetupArgument
  0.01%  1.0808ms         8  135.09us  73.608us  201.88us  cuDeviceTotalMem
  0.01%  818.74us         9  90.971us  7.2120us  326.94us  cudaMalloc
  0.00%  456.82us         8  57.102us  47.484us  69.014us  cuDeviceGetName
  0.00%  210.71us      1007     209ns     169ns  13.817us  cudaConfigureCall
  0.00%  27.584us         3  9.1940us  3.7420us  17.404us  cudaFuncGetAttributes
  0.00%  25.370us         1  25.370us  25.370us  25.370us  cudaMemset
  0.00%  25.227us         4  6.3060us  2.4390us  15.442us  cudaMemsetAsync
  0.00%  13.285us        10  1.3280us     291ns  9.7040us  cudaDeviceGetAttribute
  0.00%  3.8630us         9     429ns     194ns  1.9080us  cudaGetLastError
  0.00%  3.1540us        12     262ns     149ns     467ns  cuDeviceGet
  0.00%  2.8290us         3     943ns     228ns  2.2460us  cuDeviceGetCount
  0.00%  2.7050us         1  2.7050us  2.7050us  2.7050us  cudaGetDevice
  0.00%     927ns         1     927ns     927ns     927ns  cuInit
  0.00%     786ns         1     786ns     786ns     786ns  cuDriverGetVersion
(pytorch) [lhg256@cuda2 code]$ nvprof ./bin/conv_exp -n -a sparse ./data/1024.mat ./data/k3_0.mat 
iterations_flag = 1, alg_type_flag = sparse
Non-option argument ./data/1024.mat
Non-option argument ./data/k3_0.mat
optind:4,argc:6
==49668== NVPROF is profiling process 49668, command: ./bin/conv_exp -n -a sparse ./data/1024.mat ./data/k3_0.mat
Number of iterations: 1000
 ============= SPARSE KERNEL, TILED CONVOLUTION =============== 
Time taken to create handle: 11.170000 
Spm on device? 1
No pitch, pitch is: 0
Kernel is ALREADY on the device.
Grid dim: (64, 64), block dim: (18, 18)
Total threads: 1327104
Actual matrix width: 1024
Shared mem is: 333 elems, tile: 324, kernel: 9
Time taken to allocate mem and copy to device: 0.000000 
Time taken to execute kernel: 0.330000 
Time taken to copy memory back to host and free device mem: 0.000000 
Time taken to convert matrix: 0.020000 
Time taken to convolve matrix: 0.330000 
Time taken is 11.520000
Time taken per iteration 0.011520
==49668== Profiling application: ./bin/conv_exp -n -a sparse ./data/1024.mat ./data/k3_0.mat
==49668== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.47%  306.56ms      1000  306.56us  118.98us  2.9665ms  convolve2DKernelSparse(float*, float*, int*, int*, int, float*, int, int, int, int, int)
  0.27%  832.45us         2  416.23us  2.0480us  830.41us  [CUDA memcpy DtoH]
  0.25%  763.88us         2  381.94us  1.2800us  762.60us  [CUDA memcpy HtoD]
  0.00%  3.3920us         1  3.3920us  3.3920us  3.3920us  void cusparseIinclusive_scan_domino_v1_core<int=256, int=4>(int, int*, int*, int*, int*, int*)
  0.00%  3.2000us         1  3.2000us  3.2000us  3.2000us  void cusparseIinclusive_localscan_core<int=256, int=4>(int, int*, int*, int*)
  0.00%  3.1680us         1  3.1680us  3.1680us  3.1680us  void cusparseParseDenseByRows_kernel<float, int=0>(int, int, float const *, int, int*)
  0.00%  3.1580us         5     631ns     319ns     960ns  [CUDA memset]
  0.00%  2.9440us         1  2.9440us  2.9440us  2.9440us  void cusparseIreduce_domino_core<int=256, int=4>(int, int*, int*, int*, int*)
  0.00%  2.6240us         1  2.6240us  2.6240us  2.6240us  void cusparseDenseToCsr_kernel2<float, int=4, int=32, int=0>(int, int, float const *, int, int const *, int*, float*)
  0.00%  2.0800us         1  2.0800us  2.0800us  2.0800us  cusparseDense2CsrCopySetBase_kernel(int const *, int*, int, int)
  0.00%  1.8240us         1  1.8240us  1.8240us  1.8240us  void cusparseIinclusive_scan_merge_core<int=256, int=4>(int, int, int*, int*, int*)

==49668== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 97.07%  11.5486s        12  962.39ms  5.6660us  11.1647s  cudaFree
  2.74%  325.50ms         1  325.50ms  325.50ms  325.50ms  cudaDeviceSynchronize
  0.06%  6.9428ms         4  1.7357ms  827.45us  3.2466ms  cudaMemcpy
  0.05%  6.2306ms      1007  6.1870us  5.4230us  56.582us  cudaLaunch
  0.04%  5.0955ms       664  7.6740us     110ns  327.70us  cuDeviceGetAttribute
  0.02%  2.2735ms     11036     206ns     138ns  15.248us  cudaSetupArgument
  0.01%  1.4345ms         8  179.31us  80.046us  271.59us  cuDeviceTotalMem
  0.01%  851.63us         9  94.625us  6.9290us  343.05us  cudaMalloc
  0.00%  500.12us         8  62.514us  47.250us  74.093us  cuDeviceGetName
  0.00%  243.24us      1007     241ns     161ns  15.612us  cudaConfigureCall
  0.00%  26.776us         1  26.776us  26.776us  26.776us  cudaMemset
  0.00%  24.546us         4  6.1360us  2.3860us  14.810us  cudaMemsetAsync
  0.00%  20.796us         3  6.9320us  3.3000us  13.990us  cudaFuncGetAttributes
  0.00%  10.872us        10  1.0870us     256ns  7.5940us  cudaDeviceGetAttribute
  0.00%  4.0020us         3  1.3340us     405ns  3.1610us  cuDeviceGetCount
  0.00%  3.8850us        12     323ns     197ns     543ns  cuDeviceGet
  0.00%  3.4250us         9     380ns     150ns  1.7110us  cudaGetLastError
  0.00%  2.7140us         1  2.7140us  2.7140us  2.7140us  cudaGetDevice
  0.00%  2.2770us         1  2.2770us  2.2770us  2.2770us  cuDriverGetVersion
  0.00%  1.1140us         1  1.1140us  1.1140us  1.1140us  cuInit
(pytorch) [lhg256@cuda2 code]$ nvprof ./bin/conv_exp -n -a sparse ./data/2048.mat ./data/k3_0.mat 
iterations_flag = 1, alg_type_flag = sparse
Non-option argument ./data/2048.mat
Non-option argument ./data/k3_0.mat
optind:4,argc:6
==49693== NVPROF is profiling process 49693, command: ./bin/conv_exp -n -a sparse ./data/2048.mat ./data/k3_0.mat
Number of iterations: 1000
 ============= SPARSE KERNEL, TILED CONVOLUTION =============== 
Time taken to create handle: 10.760000 
Spm on device? 1
No pitch, pitch is: 0
Kernel is ALREADY on the device.
Grid dim: (128, 128), block dim: (18, 18)
Total threads: 5308416
Actual matrix width: 2048
Shared mem is: 333 elems, tile: 324, kernel: 9
Time taken to allocate mem and copy to device: 0.010000 
Time taken to execute kernel: 1.630000 
Time taken to copy memory back to host and free device mem: 0.010000 
Time taken to convert matrix: 0.010000 
Time taken to convolve matrix: 1.650000 
Time taken is 12.420000
Time taken per iteration 0.012420
==49693== Profiling application: ./bin/conv_exp -n -a sparse ./data/2048.mat ./data/k3_0.mat
==49693== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.10%  1.52184s      1000  1.5218ms  474.40us  4.3135ms  convolve2DKernelSparse(float*, float*, int*, int*, int, float*, int, int, int, int, int)
  0.61%  9.2962ms         2  4.6481ms  2.1760us  9.2940ms  [CUDA memcpy DtoH]
  0.29%  4.4919ms         2  2.2459ms  1.1520us  4.4907ms  [CUDA memcpy HtoD]
  0.00%  3.4880us         1  3.4880us  3.4880us  3.4880us  void cusparseIinclusive_scan_domino_v1_core<int=256, int=4>(int, int*, int*, int*, int*, int*)
  0.00%  3.2000us         1  3.2000us  3.2000us  3.2000us  void cusparseIinclusive_localscan_core<int=256, int=4>(int, int*, int*, int*)
  0.00%  3.1680us         1  3.1680us  3.1680us  3.1680us  void cusparseParseDenseByRows_kernel<float, int=0>(int, int, float const *, int, int*)
  0.00%  3.1040us         5     620ns     332ns     960ns  [CUDA memset]
  0.00%  2.8160us         1  2.8160us  2.8160us  2.8160us  void cusparseDenseToCsr_kernel2<float, int=4, int=32, int=0>(int, int, float const *, int, int const *, int*, float*)
  0.00%  2.8160us         1  2.8160us  2.8160us  2.8160us  void cusparseIreduce_domino_core<int=256, int=4>(int, int*, int*, int*, int*)
  0.00%  1.9200us         1  1.9200us  1.9200us  1.9200us  void cusparseIinclusive_scan_merge_core<int=256, int=4>(int, int, int*, int*, int*)
  0.00%  1.8560us         1  1.8560us  1.8560us  1.8560us  cusparseDense2CsrCopySetBase_kernel(int const *, int*, int, int)

==49693== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 87.00%  11.0867s        12  923.89ms  7.2780us  10.7447s  cudaFree
 12.71%  1.61997s         1  1.61997s  1.61997s  1.61997s  cudaDeviceSynchronize
  0.17%  21.137ms         4  5.2843ms  25.512us  10.550ms  cudaMemcpy
  0.04%  5.4373ms      1007  5.3990us  4.9500us  47.631us  cudaLaunch
  0.04%  4.9777ms       664  7.4960us     109ns  319.80us  cuDeviceGetAttribute
  0.01%  1.8098ms     11036     163ns     138ns  8.4000us  cudaSetupArgument
  0.01%  1.4894ms         8  186.17us  76.361us  306.70us  cuDeviceTotalMem
  0.01%  816.97us         9  90.774us  8.0920us  329.35us  cudaMalloc
  0.00%  479.22us         8  59.902us  49.269us  70.008us  cuDeviceGetName
  0.00%  192.94us      1007     191ns     166ns  12.207us  cudaConfigureCall
  0.00%  27.868us         1  27.868us  27.868us  27.868us  cudaMemset
  0.00%  27.118us         3  9.0390us  3.8000us  15.311us  cudaFuncGetAttributes
  0.00%  23.055us         4  5.7630us  2.1730us  13.808us  cudaMemsetAsync
  0.00%  11.266us        10  1.1260us     253ns  8.3530us  cudaDeviceGetAttribute
  0.00%  3.9910us         3  1.3300us     356ns  3.2580us  cuDeviceGetCount
  0.00%  3.5540us        12     296ns     198ns     483ns  cuDeviceGet
  0.00%  2.7130us         9     301ns     148ns     998ns  cudaGetLastError
  0.00%  2.7130us         1  2.7130us  2.7130us  2.7130us  cudaGetDevice
  0.00%  1.4280us         1  1.4280us  1.4280us  1.4280us  cuDriverGetVersion
  0.00%  1.0200us         1  1.0200us  1.0200us  1.0200us  cuInit